---
title: 机器学习常见算法及优缺点！
id: csdn102547902
---

点击上方“**Datawhal****e**”，选择“星标”公众号

第一时间获取价值内容

![640?](../img/8848b38b8e7e18a790e4a60c44ba9cb3.png)

### ? Index

*   决策树算法
*   分类算法
*   聚类算法
*   集成算法（AdaBoost算法）
*   人工神经网络算法
*   排序算法
*   关联规则算法（Apriori算法）

### 01 决策树算法

#### 决策树优点

1、决策树易于理解和解释，可以可视化分析，容易提取出规则。2、可以同时处理标称型和数值型数据。3、测试数据集时，运行速度比较快。4、决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。

#### 决策树缺点

1、对缺失数据处理比较困难。2、容易出现过拟合问题。3、忽略数据集中属性的相互关联。4、ID3算法计算信息增益时结果偏向数值比较多的特征。

#### 改进措施

1、对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。2、使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题。

#### 常见算法

#### 1）C4.5算法

ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：

*   用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；
*   在树构造过程中进行剪枝；
*   能处理非离散的数据；
*   能处理不完整的数据。

优点：产生的分类规则易于理解，准确率较高。缺点：1）在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效；2）C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。

#### 2）CART分类与回归树

是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。优点：1）非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。2）在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。

### 02 分类算法

#### 1）KNN算法

优点 ：1）KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练2）KNN理论简单，容易实现缺点：1）对于样本容量大的数据集计算量比较大。2）样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多。3）KNN每一次分类都会重新进行一次全局运算。4）k值大小的选择。应用领域：文本分类、模式识别、聚类分析，多分类领域

#### 2）支持向量机（SVM）

支持向量机是一种基于分类边界的方法。其基本原理是（以二维数据为例）：如果训练数据分布在二维平面上的点，它们按照其分类聚集在不同的区域。基于分类边界的分类算法的目标是，通过训练，找到这些分类之间的边界（直线的――称为线性划分，曲线的――称为非线性划分）。对于多维数据（如N维），可以将它们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面（超面比N维空间少一维）。线性分类器使用超平面类型的边界，非线性分类器使用超曲面。支持向量机的原理是将低维空间的点映射到高维空间，使它们成为线性可分，再使用线性划分的原理来判断分类边界。在高维空间中是一种线性划分，而在原有的数据空间中，是一种非线性划分。优点：1）解决小样本下机器学习问题。2）解决非线性问题。3）无局部极小值问题。（相对于神经网络等算法）4）可以很好的处理高维数据集。5）泛化能力比较强。缺点：1）对于核函数的高维映射解释力不强，尤其是径向基函数。2）对缺失数据敏感。应用领域：文本分类、图像识别、主要二分类领域

#### 3）朴素贝叶斯算法

优点：1）对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已。2）支持增量式运算。即可以实时的对新增的样本进行训练。3）朴素贝叶斯对结果解释容易理解。缺点：由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。应用领域：文本分类、欺诈检测中使用较多

#### 4）Logistic回归算法

优点：计算代价不高，易于理解和实现缺点：1）容易产生欠拟合。2）分类精度不高。应用领域：用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。

### 03 聚类算法

#### 1）K means 算法

是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k< n。算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。其中N为样本数，K是簇数，rnk b表示n属于第k个簇，uk 是第k个中心点的值。然后求出最优的uk优点： 算法速度很快缺点： 分组的数目k是一个输入参数，不合适的k可能返回较差的结果。

#### 2）EM最大期望算法

EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。

### 04 集成算法（AdaBoost算法）

#### AdaBoost算法优点

1）很好的利用了弱分类器进行级联。2）可以将不同的分类算法作为弱分类器。3）AdaBoost具有很高的精度。4）相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重。

#### Adaboost算法缺点

1）AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定。2）数据不平衡导致分类精度下降。3）训练比较耗时，每次重新选择当前分类器最好切分点。

#### AdaBoost应用领域

模式识别、计算机视觉领域，用于二分类和多分类场景

### 05 人工神经网络算法

#### 神经网络优点：

1）分类准确度高，学习能力极强。2）对噪声数据鲁棒性和容错性较强。3）有联想能力，能逼近任意非线性关系。

#### 神经网络缺点：

1）神经网络参数较多，权值和阈值。2）黑盒过程，不能观察中间结果。3）学习过程比较长，有可能陷入局部极小值。

#### 人工神经网络应用领域：

目前深度神经网络已经应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果。

### 06 排序算法（PageRank）

PageRank是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。）

#### PageRank优点：

完全独立于查询，只依赖于网页链接结构，可以离线计算。

#### PageRank缺点

1）PageRank算法忽略了网页搜索的时效性。2）旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。

### 07 关联规则算法（Apriori算法）

Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法 。Apriori算法分为两个阶段：1）寻找频繁项集2）由频繁项集找关联规则

#### 算法缺点：

1） 在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素；2） 每次计算项集的支持度时，都对数据库中    的全部记录进行了一遍扫描比较，需要很大的I/O负载。![640?wx_fmt=png](../img/77a102cc644938ab22bb0df9802930a8.png)