---
title: 当我们拿到数据进行建模时，如何选择更合适的算法？
id: csdn88316122
---

【每日一问】当我们拿到数据进行建模时，如何选择更合适的算法？
Datawhale优秀回答者：mashagua，金小楗
`目标导向`

*   机器学习
    1.先看是分类问题还是回归问题（分类就先从常用的分类模型里选择）
    2.其次，看数据特征的数据类型，然后做一些初步的数据统计，比如是否数据均衡，大致的数据分布是怎样的（不同类别的分布）
    3.然后判断用哪个比较合适一些，是树模型还是其他的分类模型。
    4.最后查看kaggle比赛有没有相似案例，别人做的方法有没有值得自己学习的地方

*   深度学习
    对于深度学习算法选择也是看任务目标选择合适的模型，图像类首选cnn及各种cnn的变种，时间顺序相关的选rnn ，生成类的选vae或gan，有明确规则的选rl。

【每日一问】什么是K-means算法？
Datawhale优秀回答者：金小楗、强
`通俗解释`
聚类算法有很多种，K-Means 是聚类算法中的最常用的一种，算法最大的特点是简单，好理解，运算速度快，但是只能应用于连续型的数据，并且一定要在聚类前需要手工指定要分成几类。

K-Means 聚类算法的大致意思就是“物以类聚，人以群分”。

首先输入 k 的值，即我们指定希望通过聚类得到 k 个分组；
从数据集中随机选取 k 个数据点作为初始大佬（质心）；
对集合中每一个小弟，计算与每一个大佬的距离，离哪个大佬距离近，就跟定哪个大佬。
这时每一个大佬手下都聚集了一票小弟，这时候召开选举大会，每一群选出新的大佬（即通过算法选出新的质心）。
如果新大佬和老大佬之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），可以认为我们进行的聚类已经达到期望的结果，算法终止。
如果新大佬和老大佬距离变化很大，需要迭代3~5步骤。
`专业解释`
K-means算法的基本思想是初始随机给定K个簇中心，按照最邻近原则把待分类样本点分到各个簇。然后按平均法重新计算各个簇的质心，
从而确定新的簇心。一直迭代，直到簇心的移动距离小于某个给定的值。
K-means聚类算法主要分为三个步骤：
(1)为待聚类的点寻找聚类中心；
(2)计算每个点到聚类中心的距离，将每个点聚类到离该点最近的聚类中去；
(3)计算每个聚类中所有点的坐标平均值，并将这个平均值作为新的聚类中心；
反复执行(2)、(3)，直到聚类中心不再进行大范围移动或者聚类次数达到要求为止。

使用K-means需要考虑的问题：
1.k如何确定
2.初始质心的选取
3.距离的度量
4.质心的计算
5.算法停止条件
6.空聚类的处理

K-means的缺陷：
K-menas算法试图找到使平凡误差准则函数最小的簇。当潜在的簇形状是凸面的，簇与簇之间区别较明显，且簇大小相近时，其聚类结果较理想。
该算法除了要事先确定簇数K和对初始聚类中心敏感外，经常以局部最优结束，同时对“噪声”和孤立点敏感，并且该方法不适于发现非凸面形状的簇或大小差别很大的簇。
K-means算法的聚类中心的个数K 需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。
K-means需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果。

K-means ++ 算法：
K-means++算法选择初始聚类中心的基本思想就是：初始的聚类中心之间的相互距离要尽可能的远。
1.从输入的数据点集合中随机选择一个点作为第一个聚类中心；
2.对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)；
3.选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大；
4.重复2和3直到k个聚类中心被选出来；
5.利用这k个初始的聚类中心来运行标准的k-means算法。

【每日一问】谈谈对分类（Classification）和预测（Prediction）的理解，主要步骤有哪些，以及两者的区别和联系。
Datawhale优秀回答者：宁静致远
一、介绍
分类：输入样本数据，输出对应的类别，将样本中每个数据对应一个已知属性。
预测：两种或者两种以上的变量之间相互依赖的函数模型，预测给定自变量对应的因变量的值。

二、步骤
分类算法分为两步：
(1)学习步：通过训练样本数据集，建立分类规则
(2)分类步：用已知的测试样本集评估分类规则的准确率，若准确率可接受，则是使用该规则对除样本以外的数据(待测样本集)进行预测。
预测算法分两步：
（1）我们先要基于一定数量的样本来训练出一个训练模型；
（2）为了判断这个模型训练的如何，我们还要对其进行检测一下；
（3）如果测试的样本数据与我们想象中的差别太大，那么我们就要重新进行训练这个预测模型，但是如果我们的预测模型符合我们的预先的期望，那么我们就可以用这个模型进行预测的操作.
三、区别
`特征`
1.分类
2.回归预测
`输出类型`
1.离散数据
2.连续数据
`目的`
1.寻找决策边界
2.找到最优拟合线
`评价方法`
1.精度、混淆矩阵
2.SEE(sum of square errors)或拟合优度

四、联系
分类算法可以预测连续值，但是连续值是以类标签的概率的形式。
预测算法可以预测离散值，但离散值以整数形式表示。