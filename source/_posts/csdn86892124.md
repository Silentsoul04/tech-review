---
title: "PyTorch 1.0 中文官方教程：序列模型和LSTM网络"
id: csdn86892124
---

> 译者：[ETCartman](https://github.com/ETCartman)

之前我们已经学过了许多的前馈网络. 所谓前馈网络, 就是网络中不会保存状态. 然而有时 这并不是我们想要的效果. 在自然语言处理 (NLP, Natural Language Processing) 中, 序列模型是一个核心的概念. 所谓序列模型, 即输入依赖于时间信息的模型. 一个典型的序列模型是隐马尔科夫模型 (HMM, Hidden Markov Model). 另一个序列模型的例子是条件随机场 (CRF, Conditional Random Field).

循环神经网络是指可以保存某种状态的神经网络. 比如说, 网络上个时刻的输出可以作为下个 时刻的输入, 这样信息就可以通过序列在网络中一直往后传递. 对于LSTM (Long-Short Term Memory) 来说, 序列中的每个元素都有一个相应的隐状态 h t h_t ht​, 该隐状态 原则上可以包含序列当前结点之前的任一节点的信息. 我们可以使用隐藏状态来预测语言模型 中的单词, 词性标签以及其他各种各样的东西.

## Pytorch中的LSTM

在正式学习之前，有几个点要说明一下，Pytorch中LSTM的输入形式是一个3D的Tensor，每一个维度都有固定的意义，第一个维度就是序列本身，第二个维度是mini-batch中实例的索引，第三个维度是输入元素的索引，我们之前没有接触过mini-batch所以我们就先假设第二维的维度是1。

如果要用"The cow jumped"这个句子来运行一个序列模型，那么就应该把它整理成如下的形式：

```
\[\begin{split}\begin{bmatrix} \overbrace{q_\text{The}}^\text{row vector} \\ q_\text{cow} \\ q_\text{jumped} \end{bmatrix}\end{split}\] 
```

除了有一个额外的大小为1的第二维度.

此外, 你还可以向网络逐个输入序列, 在这种情况下, 第一个轴的大小也是1.

来看一个简单的例子.

```
# 作者: Robert Guthrie

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.manual_seed(1) 
```

> [**阅读全文／改进本文**](https://github.com/apachecn/pytorch-doc-zh/blob/master/docs/1.0/nlp_sequence_models_tutorial.md)