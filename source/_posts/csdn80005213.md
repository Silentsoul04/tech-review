---
title: "《Scikit-Learn与TensorFlow机器学习实用指南》第15章 自编码器"
id: csdn80005213
---

# 第15章 自编码器

> 来源：[ApacheCN《Sklearn 与 TensorFlow 机器学习实用指南》翻译项目](https://github.com/apachecn/hands_on_Ml_with_Sklearn_and_TF)

> 译者：[@akonwang](https://github.com/wangxupeng)

> 校对：[@飞龙](https://github.com/wizardforcel)

自编码器是能够在无监督的情况下学习输入数据（叫做编码）的人工神经网络（即，训练集是未标记）。这些编码通常具有比输入数据低得多的维度，使得自编码器对降维有用（参见第 8 章）。更重要的是，自编码器可以作为强大的特征检测器，它们可以用于无监督的深度神经网络预训练（正如我们在第 11 章中讨论过的）。最后，他们能够随机生成与训练数据非常相似的新数据；这被称为生成模型。例如，您可以在脸部图片上训练自编码器，然后可以生成新脸部。

令人惊讶的是，自编码器只需学习将输入复制到其输出即可工作。 这听起来像是一件小事，但我们会看到以各种方式约束网络可能会让它变得相当困难。例如，您可以限制内部表示的大小，或者可以向输入添加噪声并训练网络以恢复原始输入。这些约束防止自编码器将输入直接复制到输出，这迫使它学习表示数据的有效方法。 简言之，编码是自编码器在某些限制条件下尝试学习恒等函数的副产品。
在本章中，我们将更深入地解释自编码器如何工作，可以施加什么类型的约束以及如何使用 TensorFlow 实现它们，无论是降维，特征提取，无监督预训练还是生成模型。

## [阅读全文](https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/15.%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.md)