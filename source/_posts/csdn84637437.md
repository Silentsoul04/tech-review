---
title: "Airflow 中文文档：API 参考"
id: csdn84637437
---

## 运营商

运算符允许生成某些类型的任务，这些任务在实例化时成为DAG中的节点。 所有运算符都派生自`BaseOperator` ，并以这种方式继承许多属性和方法。 有关更多详细信息，请参阅[BaseOperator](31)文档。

有三种主要类型的运营商：

*   执行操作的操作员，或告诉其他系统执行操作的操作员
*   **传输**操作员将数据从一个系统移动到另一个系
*   **传感器**是某种类型的运算符，它将一直运行直到满足某个标准。 示例包括在HDFS或S3中登陆的特定文件，在Hive中显示的分区或当天的特定时间。 传感器派生自`BaseSensorOperator`并在指定的`poke_interval`运行poke方法，直到它返回`True` 。

### BaseOperator

所有运算符都派生自`BaseOperator`并通过继承获得许多功能。 由于这是引擎的核心，因此值得花时间了解`BaseOperator`的参数，以了解可在DAG中使用的原始功能。

```
class airflow.models.BaseOperator(task_id, owner='Airflow', email=None, email_on_retry=True, email_on_failure=True, retries=0, retry_delay=datetime.timedelta(0, 300), retry_exponential_backoff=False, max_retry_delay=None, start_date=None, end_date=None, schedule_interval=None, depends_on_past=False, wait_for_downstream=False, dag=None, params=None, default_args=None, adhoc=False, priority_weight=1, weight_rule=u'downstream', queue='default', pool=None, sla=None, execution_timeout=None, on_failure_callback=None, on_success_callback=None, on_retry_callback=None, trigger_rule=u'all_success', resources=None, run_as_user=None, task_concurrency=None, executor_config=None, inlets=None, outlets=None, *args, **kwargs) 
```

基础： `airflow.utils.log.logging_mixin.LoggingMixin`

所有运营商的抽象基类。 由于运算符创建的对象成为dag中的节点，因此BaseOperator包含许多用于dag爬行行为的递归方法。 要派生此类，您需要覆盖构造函数以及“execute”方法。

> [**阅读全文／改进本文**](https://github.com/apachecn/airflow-doc-zh/blob/master/zh/31.md)