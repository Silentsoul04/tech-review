---
title: 《Scikit-Learn与TensorFlow机器学习实用指南》第16章 强化学习
id: csdn80334130
---

# 第16章 强化学习

> 来源：[ApacheCN《Sklearn 与 TensorFlow 机器学习实用指南》翻译项目](https://github.com/apachecn/hands_on_Ml_with_Sklearn_and_TF)
> 
> 译者：[@friedhelm739](https://github.com/friedhelm739)
> 
> 校对：[@飞龙](https://github.com/wizardforcel)

强化学习（RL）如今是机器学习的一大令人激动的领域，当然之前也是。自从 1950 年被发明出来后，它在这些年产生了一些有趣的应用，尤其是在游戏（例如 TD-Gammon，一个西洋双陆棋程序）和及其控制领域，但是从未弄出什么大新闻。直到 2013 年一个革命性的发展：来自英国的研究者发起了一项 Deepmind 项目，这个项目可以学习去玩任何从头开始的 Atari 游戏，甚至多数比人类玩的还要好，它仅适用像素作为输入并且没有游戏规则的任何先验知识。这是一系列令人惊叹的壮举，在 2016 年 3 月以他们的系统阿尔法狗战胜了世界围棋冠军李世石。没有一个程序能接近这个游戏的主宰，更不用说世界冠军了。今天，RL 的整个领域正在沸腾着新的想法，其都具有广泛的应用范围。DeepMind 在 2014 被谷歌以超过 5 亿美元收购。

那么他们是怎么做到的呢？事后看来，原理似乎相当简单：他们将深度学习运用到强化学习领域，结果却超越了他们最疯狂的设想。在本章中，我们将首先解释强化学习是什么，以及它擅长于什么，然后我们将介绍两个在深度强化学习领域最重要的技术：策略梯度和深度 Q 网络（DQN），包括讨论马尔可夫决策过程（MDP）。我们将使用这些技术来训练一个模型来平衡移动车上的杆子，另一个玩 Atari 游戏。同样的技术可以用于各种各样的任务，从步行机器人到自动驾驶汽车。

## [阅读全文](https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/16.%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.md)