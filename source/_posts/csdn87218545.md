---
title: "如何去实践一个完整的数据挖掘项目？"
id: csdn87218545
---

【每日一问】
如何去实践一个完整的数据挖掘项目？

*   `机器学习项目`
    1 抽象成数学问题（明确问题）
    2 获取数据
    3 特征预处理与特征选择
    4 训练模型与调优
    5 模型诊断
    6 模型融合（非必须）
    7 上线运行
    大部分机器学习项目死在第1步和第2步，平时我们说的机器学习，指的是3、4、5这3步，实践中，其实最难的是业务理解这一步，业务理解OK了，后面的一切都有章可循。

*   `NLP项目`
    1 获取语料

    已有语料：业务部门、公司积累大量的文本数据
    网上下载、抓取语料：可以通过爬虫自己去抓取一些数据，然后进行加工。

    2 语料预处理

    语料预处理大概会占到整个50%-70%的工作量，通过数据洗清、分词、词性标注、去停用词四个大的方面来完成语料的预处理工作。

    ```
     a.语料清洗：就是在语料中找到我们感兴趣的东西，把不感兴趣的视为噪音的内容清洗删除，如：对于爬取的网页内容，需要去除广告、标签、HTML、JS等代码和注解等。

      b.分词：中文语料数据为一批短文本或长文本，如：句子、文章摘要、段落或整篇文章组成的一个集合。一般句子、段落之间的字、词语是连续的，有一定含义。

      c.词性标注：就是给每个词或者词语打词类标签，如形容词、动词、名词等。这样做可以让文本在后面的处理中融入更多有用的语言信息。如，常见的文本分类就不用关心词性问题，但是类似情感分析、知识推理却是需要的

      d.去停用词：停用词一般指对文本特征没有任何贡献作用的字词，比如标点符号、语气、人称等一些词。所以在一般性的文本处理中，分词之后，接下来一步就是去停用词。但是比如在情感分析中，语气词、感叹号是应该保留的，因为他们对表示语气程度、感情色彩有一定的贡献和意义。 
    ```

    3 特征工程

    做完语料预处理之后，接下来需要考虑如何把分词之后的字和词语表示成计算机能够计算的类型。把中文分词的字符串转换成数字，有两种常用的表示模型分别是词袋模型和词向量。

    词袋模型（Bag of Word, BOW)，即不考虑词语原本在句子中的顺序，统计词频这只是最基本的方式，TF-IDF 是词袋模型的一个经典用法。

    词向量是将字、词语转换成向量矩阵的计算模型。目前为止最常用的词表示方法是 One-hot，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。还有 Google 团队的 Word2Vec，其主要包含两个模型：跳字模型（Skip-Gram）和连续词袋模型（Continuous Bag of Words，简称 CBOW），Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。除此之外，还有一些词向量的表示方式，如 Doc2Vec、WordRank 和 FastText 等。

    4 特征选择

    构造好的特征向量，是要选择合适的、表达能力强的特征。文本特征一般都是词语，具有语义信息，使用特征选择能够找出一个特征子集，其仍然可以保留语义信息；但通过特征提取找到的特征子空间，将会丢失部分语义信息。所以特征选择是一个很有挑战的过程，更多的依赖于经验和专业知识，并且有很多现成的算法来进行特征的选择

    5 模型训练

    在特征向量选择好之后，接下来就是训练模型，对于不同的应用需求，我们使用不同的模型，传统的有监督和无监督等机器学习模型， 如 KNN、SVM、Naive Bayes、决策树、GBDT、K-means 等模型；深度学习模型比如 CNN、RNN、LSTM、 Seq2Seq、FastText、TextCNN 等。这些模型在后续的分类、聚类、神经序列、情感分析等示例中都会用到。

    在模型训练时需要注意的几个点：

    ```
     1.注意过拟合、欠拟合问题，不断提高模型的泛化能力。

      2.对于神经网络，注意梯度消失和梯度爆炸问题。 
    ```

    6 评价指标

    训练好的模型，上线之前要对模型进行必要的评估，目的让模型对语料具备较好的泛化能力。具体有以下这些指标可以参考。

    错误率、精度、准确率、精确度、召回率、F1 衡量。

    错误率：是分类错误的样本数占样本总数的比例。
    精度：是分类正确的样本数占样本总数的比例。
    准确率：是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。
    精确度：是分类正确的样本数占样本总数的比例。
    召回率：是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。
    F1 衡量：表达出对查准率/查全率的不同偏好。

    7 模型上线应用

    模型线上应用，线下训练模型，然后将模型做线上部署，发布成接口服务以供业务系统使用。

【每日一问】
什么是KNN算法，它的优缺点是什么？

*   `K最近邻算法`
    如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。

*   `算法过程`：

    *   计算测试样本与每个训练样本距离；
    *   排序并选择前k个训练样本；
    *   确定前k个训练样本中各个类别的出现频率，并返回频率最高的分类作为预测分类
*   `优点`：

    *   理论成熟，思想简单，既可以用来做分类又可以做回归
    *   可以用于非线性分类
    *   训练时间复杂度比支持向量机之类的算法低
    *   和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感
    *   由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，KNN方法较其他方法更为适合
    *   该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量比较小的类域采用这种算法比较容易产生误分类情况
*   `缺点`：

    *   计算量大，尤其是特征数非常多的时候
    *   样本不平衡的时候，对稀有类别的预测准确率低
    *   KD树，球树之类的模型建立需要大量的内存
    *   是慵懒散学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢
    *   相比决策树模型，KNN模型的可解释性不强
*   `经验`：

    *   k值设定为多大？
        k太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）
        k值通常是采用交叉检验来确定（以k=1为基准）
        经验规则：k一般低于训练样本数的平方根

    *   类别如何判定最合适？
        投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。

    *   如何选择合适的距离衡量？
        高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。
        变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。

    *   训练样本是否要一视同仁？
        在训练集中，有些样本可能是更值得依赖的。
        可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。

    *   性能问题？
        kNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）。
        懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离。
        已经有一些方法提高计算的效率，例如压缩训练样本量等。

    *   能否大幅减少训练样本量，同时又保持分类精度？
        浓缩技术(condensing)
        编辑技术(editing)

【每日一问】
在python 中，数组list和元组tuple的作用和区别是什么？

*   概念解释
    `List`

    *   list是一种有序的集合，可以随时添加和删除其中的元素.
    *   用len()函数可以获得list元素的个数.
    *   还可以用-1做索引，直接获取最后一个元素, 以此类推，可以获取倒数第2个(-2)、倒数第3个(-3).
    *   支持append(),pop(),insert(),pop(i)方法．

    `Tuple`

    *   tuple和list非常类似，但是tuple一旦初始化就不能修改，因此，没有append()，insert()这样的方法．
    *   只有1个元素的tuple定义时必须加一个逗号,，来消除歧义．
    *   可以正常地使用classmates[0]，classmates[-1]，但不能赋值成另外的元素．

    `相同点与不同点`

    *   `相同点`
        元组tuple与列表List都是序列类型的容器对象，可以存放任何类型的数据、支持切片、迭代等操作。

    *   `不同点`

        *   不可变与可变：两种类型除了字面上的区别(括号与方括号)之外，最重要的一点是【tuple是不可变类型】，大小固定，而 【list 是可变类型】、数据可以动态变化，这种差异使得两者提供的方法、应用场景、性能上都有很大的区别。
        *   同样大小的数据，tuple 占用的内存空间更少
        *   tuple 对象还可作为字典的键
        *   列表一般用于存储同构数据，同构数据就是具有相同意义的数据。元组主要用于异构数据，数据库操作中查询出来的记录就是由元组构成的列表结构。
    *   `具体解释`

        *   python当时的创造者提到过要将元组看作是简单对象的组合，而把列表看作是随时间改变的数据结构；
        *   元组的不可变性提供了某种完整性，确保程序中不会被其他引用所修改；
        *   元组可以用到一些列表无法使用的地方，比如元组可以作为字典键来表示稀疏矩阵。一般来说，列表是对有时需要修改的定序集合工具，而其他需要处理固定关系的情况需要用元组