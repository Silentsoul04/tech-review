---
title: Airflow 中文文档：用Celery扩大规模
id: csdn84628777
---

`CeleryExecutor`是您扩展工人数量的方法之一。 为此，您需要设置Celery后端（ **RabbitMQ** ， **Redis** ，…）并更改`airflow.cfg`以将执行程序参数指向`CeleryExecutor`并提供相关的Celery设置。

有关设置Celery代理的更多信息，请参阅[有关该主题](http://docs.celeryproject.org/en/latest/getting-started/brokers/index.html)的详尽[Celery文档](http://docs.celeryproject.org/en/latest/getting-started/brokers/index.html) 。

以下是您的员工的一些必要要求：

*   需要安装airflow，CLI需要在路径中
*   整个群集中的气流配置设置应该是同构的
*   在worker上执行的操作符需要在该上下文中满足其依赖项。 例如，如果您使用`HiveOperator` ，则需要在该框上安装hive CLI，或者如果您使用`MySqlOperator` ，则必须以某种方式在`PYTHONPATH`提供所需的Python库
*   工作人员需要访问其`DAGS_FOLDER` ，您需要通过自己的方式同步文件系统。 常见的设置是将DAGS_FOLDER存储在Git存储库中，并使用Chef，Puppet，Ansible或用于配置环境中的计算机的任何内容在计算机之间进行同步。 如果您的所有盒子都有一个共同的挂载点，那么共享您的管道文件也应该可以正常工作

要启动工作人员，您需要设置Airflow并启动worker子命令

```
airflow worker 
```

> [**阅读全文／改进本文**](https://github.com/apachecn/airflow-doc-zh/blob/master/zh/13.md)