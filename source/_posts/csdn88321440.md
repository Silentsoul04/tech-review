---
title: "PyTorch 1.0 中文文档：常见问题解答"
id: csdn88321440
---

> 译者：[冯宝宝](https://github.com/PEGASUS1993)

## 我的模型报告“cuda runtime error(2): out of memory”

正如错误消息所示，您的GPU显存已耗尽。由于经常在PyTorch中处理大量数据，因此小错误会迅速导致程序耗尽所有GPU资源; 幸运的是，这些情况下的修复通常很简单。这里有一些常见点需要检查：

**不要在训练循环中积累历史记录。** 默认情况下，涉及需要梯度计算的变量将保留历史记录。这意味着您应该避免在计算中使用这些变量，因为这些变量将超出您的训练循环，例如，在跟踪统计数据时。相反，您应该分离变量或访问其基础数据。

有时，当可微分变量发生时，它可能是不明显的。考虑以下训练循环（从[源代码](https://discuss.pytorch.org/t/high-memory-usage-while-training/162)中删除）：

```
total_loss = 0
for i in range(10000):
    optimizer.zero_grad()
    output = model(input)
    loss = criterion(output)
    loss.backward()
    optimizer.step()
    total_loss += loss 
```

在这里，total_loss在您的训练循环中累积历史记录，因为丢失是具有自动记录历史的可微分变量。 您可以通过编写total_loss + = float（loss）来解决此问题。

此问题的其他实例：[1](https://discuss.pytorch.org/t/resolved-gpu-out-of-memory-error-with-batch-size-1/3719)。

**不要抓住你不需要的张量或变量。** 如果将张量或变量分配给本地，则在本地超出范围之前，Python不会解除分配。您可以使用`del x`释放此引用。 同样，如果将张量或向量分配给对象的成员变量，则在对象超出范围之前不会释放。如果您没有保留不需要的临时工具，您将获得最佳的内存使用量。

本地规模大小可能比您预期的要大。 例如：

```
for i in range(5):
    intermediate = f(input[i])
    result += g(intermediate)
output = h(result) 
```

> [**阅读全文／改进本文**](https://github.com/apachecn/pytorch-doc-zh/blob/master/docs/1.0/notes_faq.md)