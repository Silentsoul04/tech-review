---
title: PyTorch 1.0 中文文档：torch.distributed
id: csdn88321550
---

> 译者：[univeryinli](https://github.com/univeryinli)

## 后端

`torch.distributed` 支持三个后端，每个后端具有不同的功能。下表显示哪些功能可用于CPU/CUDA张量。仅当用于构建PyTorch的实现支持时，MPI才支持CUDA。

| 后端 | `gloo` | `mpi` | `nccl` |
| --- | --- | --- | --- |
| 设备 | CPU | GPU | CPU |
| — | — | — | — |
| 发送 | ✓ | ✘ | ✓ |
| 接收 | ✓ | ✘ | ✓ |
| 广播 | ✓ | ✓ | ✓ |
| all_reduce | ✓ | ✓ | ✓ |
| reduce | ✓ | ✘ | ✓ |
| all_gather | ✓ | ✘ | ✓ |
| 收集 | ✓ | ✘ | ✓ |
| 分散 | ✓ | ✘ | ✓ |
| 屏障 | ✓ | ✘ | ✓ |

### PyTorch附带的后端

目前PyTorch分发版仅支持Linux。默认情况下，Gloo和NCCL后端构建并包含在PyTorch的分布之中（仅在使用CUDA构建时为NCCL）。MPI是一个可选的后端，只有从源代码构建PyTorch时才能包含它。（例如，在安装了MPI的主机上构建PyTorch）

### 哪个后端使用？

在过去，我们经常被问到：“我应该使用哪个后端？”。

*   经验法则
    *   使用NCCL后端进行分布式 **GPU** 训练。
    *   使用Gloo后端进行分布式 **CPU** 训练。
*   具有InfiniBand互连的GPU主机
    *   使用NCCL，因为它是目前唯一支持InfiniBand和GPUDirect的后端。
*   GPU主机与以太网互连
    *   使用NCCL，因为它目前提供最佳的分布式GPU训练性能，特别是对于多进程单节点或多节点分布式训练。如果您遇到NCCL的任何问题，请使用Gloo作为后备选项。（请注意，Gloo目前运行速度比GPU的NCCL慢。）

> [**阅读全文／改进本文**](https://github.com/apachecn/pytorch-doc-zh/blob/master/docs/1.0/distributed.md)